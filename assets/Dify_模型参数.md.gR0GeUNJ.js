import{_ as l,c as i,o as r,ag as d}from"./chunks/framework.B-XtCDNB.js";const g=JSON.parse('{"title":"模型参数","description":"","frontmatter":{},"headers":[],"relativePath":"Dify/模型参数.md","filePath":"Dify/模型参数.md"}'),o={name:"Dify/模型参数.md"};function a(e,t,n,s,u,p){return r(),i("div",null,[...t[0]||(t[0]=[d('<h1 id="模型参数" tabindex="-1">模型参数 <a class="header-anchor" href="#模型参数" aria-label="Permalink to &quot;模型参数&quot;">​</a></h1><p>控制 <strong>模型行为和输出风格</strong></p><h3 id="温度-temperature" tabindex="-1">温度(Temperature) <a class="header-anchor" href="#温度-temperature" aria-label="Permalink to &quot;温度(Temperature)&quot;">​</a></h3><ul><li><p>控制回答的随机性、创造性</p></li><li><p>数值范围：</p><ul><li>越低：更稳定、更确定，适合客服、知识问答</li><li>越高：更发散、有创意，适合头脑风暴、写作</li></ul></li></ul><h3 id="最大标记数" tabindex="-1">最大标记数 <a class="header-anchor" href="#最大标记数" aria-label="Permalink to &quot;最大标记数&quot;">​</a></h3><ul><li>限制模型 <strong>生成的最长输出</strong></li><li>防止输出过长导致超时或费用增加</li><li>例如 512，最多返回512个token</li></ul><h3 id="功能增强" tabindex="-1">功能增强 <a class="header-anchor" href="#功能增强" aria-label="Permalink to &quot;功能增强&quot;">​</a></h3><ul><li>一些模型/服务商提供附加功能(例如工具调用、插件扩展、多模态支持)</li><li>在Dify里一般意味着可以让LLM支持 <strong>结构化输出、调用工具、更稳定的函数调用</strong></li></ul><hr><h1 id="采样与生成控制相关" tabindex="-1">采样与生成控制相关 <a class="header-anchor" href="#采样与生成控制相关" aria-label="Permalink to &quot;采样与生成控制相关&quot;">​</a></h1><ul><li><p><strong>Top K</strong></p><ul><li>从概率最高的前 K 个词中随机采样。</li><li>越小 → 更保守，越大 → 更自由。</li><li>通常搭配 Top P 使用。</li></ul></li><li><p><strong>Top P（核采样）</strong></p><ul><li>从累计概率达到 P 的候选集中采样。</li><li>常和 Top K 互斥（二选一为主）。</li></ul></li><li><p><strong>Mirostat 采样</strong></p><ul><li>一种动态采样算法，能在保持随机性的同时控制输出熵，提升文本连贯性。</li><li>比 Top P/Top K 更“稳”，适合长文本生成。</li></ul></li><li><p><strong>Repeat Penalty（重复惩罚）</strong></p><ul><li>惩罚重复 token 的概率，防止模型输出“刷屏”或啰嗦。</li><li>常见范围：1.05–1.3。</li></ul></li><li><p><strong>随机数种子（Seed）</strong></p><ul><li>控制随机性，可复现实验结果。</li><li>相同输入 + 相同 Seed → 相同输出。</li></ul></li><li><p><strong>减少标记影响（Penalize Newline / Penalize Tokens）</strong></p><ul><li>专门惩罚某些符号（比如换行、标点）出现的频率。</li><li>避免生成“每句话都换行”这种情况</li></ul></li></ul><hr><h1 id="长文本与上下文相关" tabindex="-1">长文本与上下文相关 <a class="header-anchor" href="#长文本与上下文相关" aria-label="Permalink to &quot;长文本与上下文相关&quot;">​</a></h1><p>这些参数决定模型能看多长、输出多长：</p><p><strong>最大令~牌数预测（Max Tokens / Max New Tokens）</strong></p><ul><li>控制单次生成的最大长度。</li></ul><p><strong>上下文窗口大小（Context Window Size）</strong></p><ul><li>模型一次能“记住”的上下文长度（取决于模型本身，如 LLaMA2=4k，LLaMA3=8k/32k）。</li><li>设置太大会浪费显存。</li></ul><p><strong>回溯内容（Past Context Reuse）</strong></p><ul><li>是否缓存/复用历史上下文，减少重复计算。</li><li>提升长对话性能。</li></ul><p><strong>文本连贯度（Coherence / Smoothing）</strong></p><ul><li>有些推理引擎提供此参数，调节输出更平滑、少跳跃。</li></ul><hr><h1 id="性能与硬件相关" tabindex="-1">性能与硬件相关 <a class="header-anchor" href="#性能与硬件相关" aria-label="Permalink to &quot;性能与硬件相关&quot;">​</a></h1><p>这些影响推理速度、显存占用：</p><ul><li><p><strong>GPU 层数（GPU Layers）</strong></p><ul><li>llama.cpp / ggml 模型支持的分层 offload 参数。</li><li>越多层放在 GPU，速度越快，但显存占用更高。</li></ul></li><li><p><strong>线程数（Threads）</strong></p><ul><li>控制 CPU 并行度。</li><li>多核 CPU 上能显著加速。</li></ul></li><li><p><strong>模型存活时间（Model Idle Timeout / Keepalive）</strong></p><ul><li>控制模型加载到内存后，多久不使用就卸载。</li><li>节省资源，但会导致首次请求延迟。</li></ul></li></ul><hr><h2 id="🔹-输出与格式相关" tabindex="-1">🔹 输出与格式相关 <a class="header-anchor" href="#🔹-输出与格式相关" aria-label="Permalink to &quot;🔹 输出与格式相关&quot;">​</a></h2><ul><li><p><strong>返回格式（Return Type）</strong></p><ul><li>纯文本 / JSON / 流式输出等。</li></ul></li><li><p><strong>JSON Schema</strong></p><ul><li>限定模型必须生成符合 Schema 的 JSON，确保结构化输出。</li><li>适合做 <strong>工具调用 / API 返回 / 数据提取</strong>。</li></ul></li><li><p><strong>思考模式（Reasoning Mode）</strong></p><ul><li>一些模型支持 CoT（Chain of Thought）或 ReAct 推理。</li><li>允许显式“思考过程”，提升复杂问题回答能力。</li></ul></li></ul><hr><h2 id="🔹-训练与微调相关-如果是-lora-自训练" tabindex="-1">🔹 训练与微调相关（如果是 LoRA/自训练） <a class="header-anchor" href="#🔹-训练与微调相关-如果是-lora-自训练" aria-label="Permalink to &quot;🔹 训练与微调相关（如果是 LoRA/自训练）&quot;">​</a></h2><ul><li><p><strong>学习率（Learning Rate）</strong></p><ul><li>如果你在 Dify 里连的是一个可继续微调的模型，就能看到。</li><li>控制微调时参数更新的速度。</li></ul></li></ul><p>‍</p><h1 id="📑-自建模型参数推荐配置表" tabindex="-1">📑 自建模型参数推荐配置表 <a class="header-anchor" href="#📑-自建模型参数推荐配置表" aria-label="Permalink to &quot;📑 自建模型参数推荐配置表&quot;">​</a></h1><table tabindex="0"><thead><tr><th>参数</th><th>问答（Q&amp;A）</th><th>长文写作</th><th>代码生成</th><th>创意写作</th></tr></thead><tbody><tr><td><strong>温度 (Temperature)</strong></td><td>0.1 – 0.3（稳定）</td><td>0.5 – 0.7（适度发散）</td><td>0.0 – 0.2（确定性强）</td><td>0.8 – 1.2（高创造性）</td></tr><tr><td><strong>Top P</strong></td><td>0.8 – 0.9</td><td>0.9 – 1.0</td><td>0.8 – 0.95</td><td>0.95 – 1.0</td></tr><tr><td><strong>Top K</strong></td><td>20 – 40</td><td>40 – 100</td><td>20 – 40</td><td>50 – 100</td></tr><tr><td><strong>Mirostat 采样</strong></td><td>不建议（会影响精确度）</td><td>可开 (τ=5, η=0.1) 提升连贯性</td><td>关闭</td><td>推荐开启 (τ=5–7) 保持流畅</td></tr><tr><td><strong>Repeat Penalty</strong></td><td>1.1 – 1.2（防止复读）</td><td>1.05 – 1.1</td><td>1.2 – 1.3（避免无限循环代码）</td><td>1.05 – 1.1</td></tr><tr><td><strong>最大令牌数预测 (Max Tokens)</strong></td><td>512 – 1024</td><td>2048 – 4096</td><td>1024 – 2048</td><td>2048 – 4096</td></tr><tr><td><strong>上下文窗口大小</strong></td><td>≥4k（建议8k以上）</td><td>16k – 32k（长文需求）</td><td>≥8k（长代码依赖上下文）</td><td>8k – 16k</td></tr><tr><td><strong>随机数种子 (Seed)</strong></td><td>固定（保证一致性）</td><td>可随机</td><td>固定（方便复现）</td><td>随机（避免重复）</td></tr><tr><td><strong>GPU 层数</strong></td><td>尽量多（提速）</td><td>尽量多（长文本对显存压力大）</td><td>尽量多</td><td>可调（性能优先）</td></tr><tr><td><strong>线程数</strong></td><td>CPU = 物理核数</td><td>CPU = 核数×2（长文本快）</td><td>CPU = 核数</td><td>CPU = 核数</td></tr><tr><td><strong>模型存活时间</strong></td><td>30–60 min</td><td>≥2h（减少频繁加载）</td><td>30–60 min</td><td>≥1h</td></tr><tr><td><strong>返回格式</strong></td><td>纯文本 / JSON</td><td>纯文本</td><td>JSON Schema（结构化代码）</td><td>纯文本</td></tr><tr><td><strong>JSON Schema</strong></td><td>可选（结构化问答）</td><td>不需要</td><td>强烈推荐（函数调用 / AST 格式）</td><td>不需要</td></tr><tr><td><strong>思考模式 (Reasoning Mode)</strong></td><td>可开（提升复杂推理）</td><td>关闭（防止跑题）</td><td>可开（帮助解释代码逻辑）</td><td>可开（丰富故事走向）</td></tr></tbody></table><hr><h2 id="🎯-使用建议" tabindex="-1">🎯 使用建议 <a class="header-anchor" href="#🎯-使用建议" aria-label="Permalink to &quot;🎯 使用建议&quot;">​</a></h2><ul><li><p><strong>问答（Q&amp;A）</strong></p><ul><li>目标：准确、稳定。</li><li>参数：低温度 + 较小 Top K/P，保证确定性。</li></ul></li><li><p><strong>长文写作</strong></p><ul><li>目标：流畅、上下文连贯。</li><li>参数：中等温度 + 较大上下文窗口 + Mirostat。</li></ul></li><li><p><strong>代码生成</strong></p><ul><li>目标：精确、可复现。</li><li>参数：温度接近 0，强制确定性输出 + Repeat Penalty 防止死循环。</li></ul></li><li><p><strong>创意写作</strong></p><ul><li>目标：发散、风格化。</li><li>参数：高温度 + 较大 Top K/P + Mirostat 提升故事性。</li></ul></li></ul><hr><p>⚡ 提示：这些参数可以先用“推荐区间”的中间值，然后根据你机器性能 &amp; 模型特点微调。</p>',40)])])}const c=l(o,[["render",a]]);export{g as __pageData,c as default};
